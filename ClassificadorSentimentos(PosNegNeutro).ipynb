{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97xbtp5gsCSp"
   },
   "source": [
    "# Processamento e análise dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mh02JyTzl5Ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/karine/anaconda3/lib/python3.7/site-packages (3.4.5)\r\n",
      "Requirement already satisfied: six in /home/karine/anaconda3/lib/python3.7/site-packages (from nltk) (1.14.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/karine/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/karine/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preparando ambiente (importando bibliotecas e downloads...)\n",
    "\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('rslp')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVekMU8El5Ek",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importando dataset\n",
    "df = pd.read_csv(\"dataset.csv\", sep=\",\" , encoding=\"utf8\")\n",
    "df = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_pt</th>\n",
       "      <th>Competitivo</th>\n",
       "      <th>Ofensivo</th>\n",
       "      <th>Rebelde</th>\n",
       "      <th>Retraído</th>\n",
       "      <th>Subsequente</th>\n",
       "      <th>Cooperativo</th>\n",
       "      <th>Ajudante</th>\n",
       "      <th>Líder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uma coisa engraçada aconteceu comigo enquanto ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Este filme de terror alemão tem que ser um dos...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sendo um fã de longa data do cinema japonês, e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Tokyo Eyes\" fala de uma menina japonesa de 17...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fazendeiros ricos em Buenos Aires têm uma long...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_pt  Competitivo  Ofensivo  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...          0.0       0.0   \n",
       "1  Este é um exemplo do motivo pelo qual a maiori...          0.0       0.0   \n",
       "2  Primeiro de tudo eu odeio esses raps imbecis, ...          0.0       0.0   \n",
       "3  Nem mesmo os Beatles puderam escrever músicas ...          0.0       0.0   \n",
       "4  Filmes de fotos de latão não é uma palavra apr...          0.0       0.0   \n",
       "5  Uma coisa engraçada aconteceu comigo enquanto ...          0.0       0.0   \n",
       "6  Este filme de terror alemão tem que ser um dos...          0.0       0.0   \n",
       "7  Sendo um fã de longa data do cinema japonês, e...          0.0       0.0   \n",
       "8  \"Tokyo Eyes\" fala de uma menina japonesa de 17...          0.0       0.0   \n",
       "9  Fazendeiros ricos em Buenos Aires têm uma long...          0.0       0.0   \n",
       "\n",
       "   Rebelde  Retraído  Subsequente  Cooperativo  Ajudante  Líder  \n",
       "0      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "1      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "2      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "3      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "4      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "5      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "6      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "7      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "8      0.0       0.0          0.0          0.0       0.0    0.0  \n",
       "9      0.0       0.0          0.0          0.0       0.0    0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_words = open('degree-words.txt','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHxwzjayl5Er"
   },
   "source": [
    "### Removendo e tratando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3731,
     "status": "ok",
     "timestamp": 1561491232940,
     "user": {
      "displayName": "Wesley Watanabe",
      "photoUrl": "https://lh6.googleusercontent.com/-n9tJsaNisS0/AAAAAAAAAAI/AAAAAAAAJMg/nqhIYX_GgmI/s64/photo.jpg",
      "userId": "07895704557374551617"
     },
     "user_tz": 180
    },
    "id": "jnEgbdaWl5Er",
    "outputId": "f0b10cc4-dd53-49da-c3b1-43f5fed6522e"
   },
   "outputs": [],
   "source": [
    "# Remove columns e create column\n",
    "df.drop(columns=['id', 'text_en', 'sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Léxicos de Sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_lexico = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentilexpt = open('SentiLex-lem-PT02.txt','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sentilexpt:\n",
    "    pos_ponto = i.find('.')\n",
    "    palavra = (i[:pos_ponto])\n",
    "    pol_pos = i.find('POL')\n",
    "    polaridade = (i[pol_pos+7:pol_pos+9]).replace(';','')\n",
    "    dicionario_lexico[palavra] = polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontolp = open('lexico_v3.0.txt','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ontolp:\n",
    "    split_dic = i.split(',')\n",
    "    palavra = split_dic[0]\n",
    "    if palavra not in dicionario_lexico:\n",
    "        polaridade = split_dic[2]\n",
    "        dicionario_lexico[palavra] = polaridade        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_words = open('degree-words.txt','r', encoding='utf8')\n",
    "degree_words_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in degree_words:\n",
    "    split_dic = i.split(';')\n",
    "    degree_words_set[split_dic[0]] = split_dic[1][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': 4, 'neutro': 0, 'neg': 0}\n",
      "{'pos': 4, 'neutro': 2, 'neg': -2}\n",
      "{'pos': 0, 'neutro': 0, 'neg': -7}\n",
      "{'pos': 3, 'neutro': 0, 'neg': 0}\n",
      "{'pos': 10, 'neutro': 6, 'neg': 0}\n",
      "{'pos': 0, 'neutro': 2, 'neg': -3}\n",
      "{'pos': 6, 'neutro': 0, 'neg': -11}\n",
      "{'pos': 20, 'neutro': 5, 'neg': -14}\n",
      "{'pos': 0, 'neutro': 8, 'neg': 0}\n",
      "{'pos': 4, 'neutro': 6, 'neg': -6}\n"
     ]
    }
   ],
   "source": [
    "for frase in df['text_pt']:\n",
    "    \n",
    "    frase = nlp(frase)\n",
    "    degree_words_head = []\n",
    "    degree_words_aux = []\n",
    "    score_frase = {'pos':0, 'neutro':0, 'neg':0}\n",
    "    \n",
    "    for token in frase:\n",
    "        if(token.text in degree_words_set):\n",
    "            degree_words_head.append(token.head.text)\n",
    "            degree_words_aux.append(int(degree_words_set.get(token.text)))\n",
    "            \n",
    "    for token in frase:\n",
    "        if(token.text in dicionario_lexico):\n",
    "            if token.head.text in degree_words_head:\n",
    "                dic = int(dicionario_lexico.get(token.text))\n",
    "                neg = int(degree_words_aux[degree_words_head.index(token.head.text)])                   \n",
    "                if dic == +1:\n",
    "                    score_frase['pos'] = int(score_frase.get('pos')) + dic + neg\n",
    "                elif dic == -1:\n",
    "                    score_frase['neg'] = int(score_frase.get('neg')) + dic - neg\n",
    "                else:\n",
    "                    score_frase['neutro'] = int(score_frase.get('neutro')) + dic + neg\n",
    "    print(score_frase)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "NPL.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
