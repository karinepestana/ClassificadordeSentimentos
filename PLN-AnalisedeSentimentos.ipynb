{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/karine/anaconda3/lib/python3.7/site-packages (3.4.5)\r\n",
      "Requirement already satisfied: six in /home/karine/anaconda3/lib/python3.7/site-packages (from nltk) (1.14.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/karine/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/karine/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preparando ambiente (importando bibliotecas e downloads...)\n",
    "\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('rslp')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97xbtp5gsCSp"
   },
   "source": [
    "# Tratamento Dados Originais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLogs_Original = open('logs/LogGeral_Original.txt', 'r', encoding='utf8')\\nArquivo_Preprocessado = open('logs/LogGeral_PreProcessado.txt', 'w+')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logs_Original = open('logs/LogGeral_Original.txt', 'r', encoding='utf8')\n",
    "Arquivo_Preprocessado = open('logs/LogGeral_PreProcessado.txt', 'w+')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nagente = ''\\nfor i in Logs_Original:\\n    novo_agente = 'nulo'\\n    #print('oi')\\n    if (i[-11:] == '06/01/2020\\n') or (i[-11:] == '06/02/2020\\n'):\\n        novo_agente = i[:-11]\\n\\n    if novo_agente == 'nulo':\\n        Arquivo_Preprocessado.writelines(str(agente + '\\t' + i))\\n    else: \\n        if novo_agente == 'AgAt1 - Juliano Storch':\\n            agente = 'AgAT1'\\n        elif novo_agente == 'AgAt2':\\n            agente = 'AgAT2'\\n        elif novo_agente == 'AgCD1 - Fiscal Cidadela':\\n            agente = 'AgCD1|Fiscal CD'\\n        elif novo_agente == 'AgCD2 / PrefeitoCD - GustavoLima':\\n            agente = 'AgCD2|Prefeito CD'\\n        elif novo_agente == 'AgCD3 | VerCD':\\n            agente = 'AgCD3|Vereador CD'\\n        elif novo_agente == 'EmpMaq - PrefeitaATLANTIS':\\n            agente = 'EmpMaq|Prefeito AT'\\n        elif novo_agente == 'EmpSem / Fiscal - Bruno':\\n            agente = 'EmpSem|Fiscal AT'  \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "agente = ''\n",
    "for i in Logs_Original:\n",
    "    novo_agente = 'nulo'\n",
    "    #print('oi')\n",
    "    if (i[-11:] == '06/01/2020\\n') or (i[-11:] == '06/02/2020\\n'):\n",
    "        novo_agente = i[:-11]\n",
    "\n",
    "    if novo_agente == 'nulo':\n",
    "        Arquivo_Preprocessado.writelines(str(agente + '\\t' + i))\n",
    "    else: \n",
    "        if novo_agente == 'AgAt1 - Juliano Storch':\n",
    "            agente = 'AgAT1'\n",
    "        elif novo_agente == 'AgAt2':\n",
    "            agente = 'AgAT2'\n",
    "        elif novo_agente == 'AgCD1 - Fiscal Cidadela':\n",
    "            agente = 'AgCD1|Fiscal CD'\n",
    "        elif novo_agente == 'AgCD2 / PrefeitoCD - GustavoLima':\n",
    "            agente = 'AgCD2|Prefeito CD'\n",
    "        elif novo_agente == 'AgCD3 | VerCD':\n",
    "            agente = 'AgCD3|Vereador CD'\n",
    "        elif novo_agente == 'EmpMaq - PrefeitaATLANTIS':\n",
    "            agente = 'EmpMaq|Prefeito AT'\n",
    "        elif novo_agente == 'EmpSem / Fiscal - Bruno':\n",
    "            agente = 'EmpSem|Fiscal AT'  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLogs_Original.close()\\nArquivo_Preprocessado.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logs_Original.close()\n",
    "Arquivo_Preprocessado.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e tratamento dos léxicos e datasets necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_lexico = {}\n",
    "sentilexpt = open('SentiLex-lem-PT02.txt','r', encoding='utf8')\n",
    "ontolp = open('lexico_v3.0.txt','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sentilexpt:\n",
    "    pos_ponto = i.find('.')\n",
    "    palavra = (i[:pos_ponto])\n",
    "    pol_pos = i.find('POL')\n",
    "    polaridade = (i[pol_pos+7:pol_pos+9]).replace(';','')\n",
    "    dicionario_lexico[palavra] = polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ontolp:\n",
    "    split_dic = i.split(',')\n",
    "    palavra = split_dic[0]\n",
    "    if palavra not in dicionario_lexico:\n",
    "        polaridade = split_dic[2]\n",
    "        dicionario_lexico[palavra] = polaridade        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_words = open('degree-words.txt','r', encoding='utf8')\n",
    "degree_words_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in degree_words:\n",
    "    split_dic = i.split(';')\n",
    "    degree_words_set[split_dic[0]] = split_dic[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentilexpt.close()\n",
    "ontolp.close()\n",
    "degree_words.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = pd.read_csv(\"LIWC2007.txt\",sep=\"\\t\",encoding=\"ISO-8859-1\", names=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_set = {}\n",
    "def cria_dic_liwc(x):\n",
    "    lista = []\n",
    "    if 126 in list(x):\n",
    "        liwc_set[x.name] = 'pos'\n",
    "    elif 127 in list(x):\n",
    "        liwc_set[x.name] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a          None\n",
       "aba        None\n",
       "abafa      None\n",
       "abafad*    None\n",
       "abafada    None\n",
       "           ... \n",
       "último     None\n",
       "último*    None\n",
       "út*        None\n",
       "úteis      None\n",
       "útil       None\n",
       "Length: 127161, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.apply(lambda x: cria_dic_liwc(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.read_csv(\"logs/LogGeral_PreProcessado.txt\", sep=\"\\t\" , encoding=\"utf8\", names=['Agente', 'Frase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
       "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>49456</td>\n",
       "      <td>Seeing as the vote average was pretty low, and...</td>\n",
       "      <td>Como a média de votos era muito baixa, e o fat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>49457</td>\n",
       "      <td>The plot had some wretched, unbelievable twist...</td>\n",
       "      <td>O enredo teve algumas reviravoltas infelizes e...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>49458</td>\n",
       "      <td>I am amazed at how this movieand most others h...</td>\n",
       "      <td>Estou espantado com a forma como este filme e ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>49459</td>\n",
       "      <td>A Christmas Together actually came before my t...</td>\n",
       "      <td>A Christmas Together realmente veio antes do m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>49460</td>\n",
       "      <td>Working-class romantic drama from director Mar...</td>\n",
       "      <td>O drama romântico da classe trabalhadora do di...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3959 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            text_en  \\\n",
       "0         1  Once again Mr. Costner has dragged out a movie...   \n",
       "1         2  This is an example of why the majority of acti...   \n",
       "2         3  First of all I hate those moronic rappers, who...   \n",
       "3         4  Not even the Beatles could write songs everyon...   \n",
       "4         5  Brass pictures movies is not a fitting word fo...   \n",
       "...     ...                                                ...   \n",
       "3954  49456  Seeing as the vote average was pretty low, and...   \n",
       "3955  49457  The plot had some wretched, unbelievable twist...   \n",
       "3956  49458  I am amazed at how this movieand most others h...   \n",
       "3957  49459  A Christmas Together actually came before my t...   \n",
       "3958  49460  Working-class romantic drama from director Mar...   \n",
       "\n",
       "                                                text_pt sentiment  \n",
       "0     Mais uma vez, o Sr. Costner arrumou um filme p...       neg  \n",
       "1     Este é um exemplo do motivo pelo qual a maiori...       neg  \n",
       "2     Primeiro de tudo eu odeio esses raps imbecis, ...       neg  \n",
       "3     Nem mesmo os Beatles puderam escrever músicas ...       neg  \n",
       "4     Filmes de fotos de latão não é uma palavra apr...       neg  \n",
       "...                                                 ...       ...  \n",
       "3954  Como a média de votos era muito baixa, e o fat...       pos  \n",
       "3955  O enredo teve algumas reviravoltas infelizes e...       pos  \n",
       "3956  Estou espantado com a forma como este filme e ...       pos  \n",
       "3957  A Christmas Together realmente veio antes do m...       pos  \n",
       "3958  O drama romântico da classe trabalhadora do di...       pos  \n",
       "\n",
       "[3959 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxa de sentimento por frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\", sep=\",\" , encoding=\"utf8\")\n",
    "df.drop(columns=['id', 'text_en', 'sentiment'], axis=1, inplace=True)\n",
    "df = df[:100]\n",
    "\n",
    "lista_score_res = []\n",
    "\n",
    "for frase in df['text_pt']:\n",
    "    \n",
    "    frase = nlp(frase)\n",
    "    degree_words_head = []\n",
    "    degree_words_aux = []\n",
    "    score_frase = {'pos':0, 'neg':0}\n",
    "    \n",
    "    for token in frase:\n",
    "        if(token.text in degree_words_set):\n",
    "            degree_words_head.append(token.head.text)\n",
    "            degree_words_aux.append(int(degree_words_set.get(token.text)))\n",
    "            \n",
    "    for token in frase:\n",
    "        if(token.text in liwc_set):\n",
    "            dic = liwc_set.get(token.text)\n",
    "            neg = 0\n",
    "            if token.head.text in degree_words_head:                \n",
    "                neg = int(degree_words_aux[degree_words_head.index(token.head.text)])\n",
    "            if dic == 'pos':\n",
    "                score_frase['pos'] = int(score_frase.get('pos')) + 1 + neg\n",
    "            else:\n",
    "                score_frase['neg'] = int(score_frase.get('neg')) - 1 - neg\n",
    "\n",
    "    score_resultado = (0, 0)\n",
    "    for sentimento, valor in score_frase.items():\n",
    "        s, v = score_resultado\n",
    "        if abs(valor) > v:\n",
    "            score_resultado = (sentimento, valor)\n",
    "        \n",
    "    s, v = score_resultado\n",
    "    lista_score_res.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classificacao'] = lista_score_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "NPL.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
