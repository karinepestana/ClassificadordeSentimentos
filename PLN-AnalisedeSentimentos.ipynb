{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/karine/anaconda3/lib/python3.7/site-packages (3.4.5)\r\n",
      "Requirement already satisfied: six in /home/karine/anaconda3/lib/python3.7/site-packages (from nltk) (1.14.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/karine/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/karine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/karine/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preparando ambiente (importando bibliotecas e downloads...)\n",
    "\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('rslp')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97xbtp5gsCSp"
   },
   "source": [
    "# Tratamento Dados Originais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLogs_Original = open('logs/LogGeral_Original.txt', 'r', encoding='utf8')\\nArquivo_Preprocessado = open('logs/LogGeral_PreProcessado.txt', 'w+')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logs_Original = open('logs/LogGeral_Original.txt', 'r', encoding='utf8')\n",
    "Arquivo_Preprocessado = open('logs/LogGeral_PreProcessado.txt', 'w+')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nagente = ''\\nfor i in Logs_Original:\\n    novo_agente = 'nulo'\\n    #print('oi')\\n    if (i[-11:] == '06/01/2020\\n') or (i[-11:] == '06/02/2020\\n'):\\n        novo_agente = i[:-11]\\n\\n    if novo_agente == 'nulo':\\n        Arquivo_Preprocessado.writelines(str(agente + '\\t' + i))\\n    else: \\n        if novo_agente == 'AgAt1 - Juliano Storch':\\n            agente = 'AgAT1'\\n        elif novo_agente == 'AgAt2':\\n            agente = 'AgAT2'\\n        elif novo_agente == 'AgCD1 - Fiscal Cidadela':\\n            agente = 'AgCD1|Fiscal CD'\\n        elif novo_agente == 'AgCD2 / PrefeitoCD - GustavoLima':\\n            agente = 'AgCD2|Prefeito CD'\\n        elif novo_agente == 'AgCD3 | VerCD':\\n            agente = 'AgCD3|Vereador CD'\\n        elif novo_agente == 'EmpMaq - PrefeitaATLANTIS':\\n            agente = 'EmpMaq|Prefeito AT'\\n        elif novo_agente == 'EmpSem / Fiscal - Bruno':\\n            agente = 'EmpSem|Fiscal AT'  \\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "agente = ''\n",
    "for i in Logs_Original:\n",
    "    novo_agente = 'nulo'\n",
    "    #print('oi')\n",
    "    if (i[-11:] == '06/01/2020\\n') or (i[-11:] == '06/02/2020\\n'):\n",
    "        novo_agente = i[:-11]\n",
    "\n",
    "    if novo_agente == 'nulo':\n",
    "        Arquivo_Preprocessado.writelines(str(agente + '\\t' + i))\n",
    "    else: \n",
    "        if novo_agente == 'AgAt1 - Juliano Storch':\n",
    "            agente = 'AgAT1'\n",
    "        elif novo_agente == 'AgAt2':\n",
    "            agente = 'AgAT2'\n",
    "        elif novo_agente == 'AgCD1 - Fiscal Cidadela':\n",
    "            agente = 'AgCD1|Fiscal CD'\n",
    "        elif novo_agente == 'AgCD2 / PrefeitoCD - GustavoLima':\n",
    "            agente = 'AgCD2|Prefeito CD'\n",
    "        elif novo_agente == 'AgCD3 | VerCD':\n",
    "            agente = 'AgCD3|Vereador CD'\n",
    "        elif novo_agente == 'EmpMaq - PrefeitaATLANTIS':\n",
    "            agente = 'EmpMaq|Prefeito AT'\n",
    "        elif novo_agente == 'EmpSem / Fiscal - Bruno':\n",
    "            agente = 'EmpSem|Fiscal AT'  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLogs_Original.close()\\nArquivo_Preprocessado.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Logs_Original.close()\n",
    "Arquivo_Preprocessado.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento e tratamento dos léxicos e datasets necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionario_lexico = {}\n",
    "sentilexpt = open('SentiLex-lem-PT02.txt','r', encoding='utf8')\n",
    "ontolp = open('lexico_v3.0.txt','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sentilexpt:\n",
    "    pos_ponto = i.find('.')\n",
    "    palavra = (i[:pos_ponto])\n",
    "    pol_pos = i.find('POL')\n",
    "    polaridade = (i[pol_pos+7:pol_pos+9]).replace(';','')\n",
    "    dicionario_lexico[palavra] = polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ontolp:\n",
    "    split_dic = i.split(',')\n",
    "    palavra = split_dic[0]\n",
    "    if palavra not in dicionario_lexico:\n",
    "        polaridade = split_dic[2]\n",
    "        dicionario_lexico[palavra] = polaridade        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_words = open('degree-words.txt','r', encoding='utf8')\n",
    "degree_words_set = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in degree_words:\n",
    "    split_dic = i.split(';')\n",
    "    degree_words_set[split_dic[0]] = split_dic[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentilexpt.close()\n",
    "ontolp.close()\n",
    "degree_words.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = pd.read_csv(\"LIWC2007.txt\",sep=\"\\t\",encoding=\"ISO-8859-1\", names=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_set = {}\n",
    "def cria_dic_liwc(x):\n",
    "    lista = []\n",
    "    if 126 in list(x):\n",
    "        liwc_set[x.name] = 'pos'\n",
    "    elif 127 in list(x):\n",
    "        liwc_set[x.name] = 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a          None\n",
       "aba        None\n",
       "abafa      None\n",
       "abafad*    None\n",
       "abafada    None\n",
       "           ... \n",
       "último     None\n",
       "último*    None\n",
       "út*        None\n",
       "úteis      None\n",
       "útil       None\n",
       "Length: 127161, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.apply(lambda x: cria_dic_liwc(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.read_csv(\"logs/LogGeral_PreProcessado.txt\", sep=\"\\t\" , encoding=\"utf8\", names=['Agente', 'Frase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxa de sentimento por frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"dataset.csv\", sep=\",\" , encoding=\"utf8\")\n",
    "#df.drop(columns=['id', 'text_en', 'sentiment'], axis=1, inplace=True)\n",
    "#df = df[:100]\n",
    "\n",
    "lista_score_res = []\n",
    "\n",
    "for frase in logs['Frase']:\n",
    "    \n",
    "    frase = nlp(frase)\n",
    "    degree_words_head = []\n",
    "    degree_words_aux = []\n",
    "    score_frase = {'pos':0, 'neg':0}\n",
    "    \n",
    "    for token in frase:\n",
    "        if(token.text in degree_words_set):\n",
    "            degree_words_head.append(token.head.text)\n",
    "            degree_words_aux.append(int(degree_words_set.get(token.text)))\n",
    "            \n",
    "    for token in frase:\n",
    "        if(token.text in liwc_set):\n",
    "            dic = liwc_set.get(token.text)\n",
    "            neg = 0\n",
    "            if token.head.text in degree_words_head:                \n",
    "                neg = int(degree_words_aux[degree_words_head.index(token.head.text)])\n",
    "            score_frase[dic] = int(score_frase.get(dic)) + 1 + neg\n",
    "\n",
    "    score_resultado = ('neutro', 0)\n",
    "    for sentimento, valor in score_frase.items():\n",
    "        s, v = score_resultado\n",
    "        if abs(valor) > v:\n",
    "            score_resultado = (sentimento, valor)\n",
    "        \n",
    "    s, v = score_resultado\n",
    "    lista_score_res.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs['Sentimento'] = lista_score_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agente</th>\n",
       "      <th>Frase</th>\n",
       "      <th>Sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AgAT1</td>\n",
       "      <td>Não tenho interesse em me candidatar</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AgAT2</td>\n",
       "      <td>então fica como ta ?</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgAT2</td>\n",
       "      <td>tipo a unica posibilidade  é ou o outro|a agri...</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AgAT2</td>\n",
       "      <td>e ja deixo claro q pra mim tanto faz</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EmpMaq|Prefeito AT</td>\n",
       "      <td>pra mim tanto faz tbm</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>AgCD3|Vereador CD</td>\n",
       "      <td>hahhhahhaa</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>AgCD3|Vereador CD</td>\n",
       "      <td>concordo com as decisões q o prefeito tomar</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>AgCD3|Vereador CD</td>\n",
       "      <td>pessoal até mais</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>AgCD2|Prefeito CD</td>\n",
       "      <td>até mais gente</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>AgCD3|Vereador CD</td>\n",
       "      <td>Até mais :slight_smile: :thumbsup:</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Agente                                              Frase  \\\n",
       "0                 AgAT1               Não tenho interesse em me candidatar   \n",
       "1                 AgAT2                               então fica como ta ?   \n",
       "2                 AgAT2  tipo a unica posibilidade  é ou o outro|a agri...   \n",
       "3                 AgAT2               e ja deixo claro q pra mim tanto faz   \n",
       "4    EmpMaq|Prefeito AT                              pra mim tanto faz tbm   \n",
       "..                  ...                                                ...   \n",
       "991   AgCD3|Vereador CD                                         hahhhahhaa   \n",
       "992   AgCD3|Vereador CD        concordo com as decisões q o prefeito tomar   \n",
       "993   AgCD3|Vereador CD                                   pessoal até mais   \n",
       "994   AgCD2|Prefeito CD                                     até mais gente   \n",
       "995   AgCD3|Vereador CD                 Até mais :slight_smile: :thumbsup:   \n",
       "\n",
       "    Sentimento  \n",
       "0       neutro  \n",
       "1       neutro  \n",
       "2       neutro  \n",
       "3          pos  \n",
       "4       neutro  \n",
       "..         ...  \n",
       "991     neutro  \n",
       "992        pos  \n",
       "993     neutro  \n",
       "994     neutro  \n",
       "995     neutro  \n",
       "\n",
       "[996 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords():\n",
    "    frases = []\n",
    "    for (palavras, sentimento) in zip(logs.Frase, logs.Sentimento):\n",
    "        semStop = [ p for p in palavras.split() if p not in stop_words]\n",
    "        frases.append((semStop, sentimento))\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realiza_stem(dados):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frases_sem_Stemming = []\n",
    "    for (palavras, sentimento) in dados:\n",
    "        com_Stemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in stop_words]\n",
    "        frases_sem_Stemming.append((com_Stemming, sentimento))\n",
    "    return pd.DataFrame(frases_sem_Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessamento():\n",
    "    sem_stopwords = removeStopWords()    \n",
    "    return realiza_stem(sem_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(ngram_range=(1, 1))\n",
    "vect.fit(logs.Frase)\n",
    "text_vect = vect.transform(logs.Frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(text_vect, logs.Sentimento, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='newton-cg')\n",
    "#y=y.astype('int')\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8168145682451682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_prediction = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_prediction, y_test, average='weighted')\n",
    "\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "NPL.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
